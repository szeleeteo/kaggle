{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = \"data/demand-forecasting/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True, time=False):\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def apply_cats(df, trn):\n",
    "    for n,c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def smape(y_pred,y_true):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_scores(pred,label):\n",
    "    rmse = np.sqrt(mean_squared_error(pred,label))\n",
    "    mae = mean_absolute_error(pred,label)\n",
    "    smape_score = smape(pred,label)\n",
    "    \n",
    "    print('RMSE: ' + str(rmse))\n",
    "    print('MAE: ' + str(mae))\n",
    "    print('SMAPE: ' + str(smape_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_preds(pred,label):  \n",
    "    \n",
    "    plt.xlabel('Actual Y ')\n",
    "    plt.ylabel('Predicted Y')\n",
    "    \n",
    "    x = np.linspace(0.0, 200.0)\n",
    "    y = x\n",
    "    plt.plot(x, y, 'r')\n",
    "    \n",
    "    plt.scatter(label,pred,alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{PATH}train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv(f'{PATH}test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "add_datepart(train, 'date',drop=False)\n",
    "add_datepart(test, 'date', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_vars = ['store', 'item', 'Month', 'Week', 'Day','Dayofweek', 'Dayofyear']\n",
    "contin_vars = ['Year', 'Elapsed'] \n",
    "\n",
    "# Elapsed = Unix Timestamp ( 0 = 1 Jan 1970 12.00am and can be negative)\n",
    "# Discared date categorical variables\n",
    "# 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start','Is_year_end', 'Is_year_start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reorg train and test dataset\n",
    "dependent = 'sales'\n",
    "train = train[cat_vars+contin_vars+[dependent, 'date']].copy()\n",
    "\n",
    "test[dependent] = 0 # broadcast zero for 'Sales' dummy col\n",
    "test = test[cat_vars+contin_vars+[dependent, 'date', 'id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for v in cat_vars: train[v] = train[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "apply_cats(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for v in contin_vars:\n",
    "    train[v] = train[v].fillna(0).astype('float32')\n",
    "    test[v] = test[v].fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sales = train['sales'].copy()\n",
    "train.drop(columns=['date','sales'],inplace=True)\n",
    "test.drop(columns=['date','sales','id'],inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "We expect sales to be what they were at the same time of year, in the past, for each store+item combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df[\"median-store_item-month\"] = df.groupby(['Month',\"item\",\"store\"])[\"sales\"].transform(\"median\") # median sales for particular item-store combo\n",
    "#df[\"median-store_item-week\"] = df.groupby(['Week',\"item\",\"store\"])[\"sales\"].transform(\"median\") # median sales for particular item-store combo\n",
    "#df[\"median-store_item-dayofweek\"] = df.groupby(['Dayofweek',\"item\",\"store\"])[\"sales\"].transform(\"median\") # median sales for particular item-store combo\n",
    "\n",
    "df[\"mean-store_item-month\"] = df.groupby(['Month',\"item\",\"store\"])[\"sales\"].transform(\"mean\") # mean sales for particular item-store combo\n",
    "df[\"mean-store_item-week\"] = df.groupby(['Week',\"item\",\"store\"])[\"sales\"].transform(\"mean\") # mean sales for particular item-store combo\n",
    "df[\"mean-store_item-dayofweek-month\"] = df.groupby(['Dayofweek','Month',\"item\",\"store\"])[\"sales\"].transform(\"mean\") # mean sales for particular item-store combo\n",
    "\n",
    "#df[\"item-month-sum\"] = df.groupby(['Month',\"item\"])[\"sales\"].transform(\"sum\") # total sales of that item  for all stores\n",
    "#df[\"store-month-sum\"] = df.groupby(['Month',\"store\"])[\"sales\"].transform(\"sum\") # total sales of that store  for all items\n",
    "\n",
    "#df[\"item-week-sum\"] = df.groupby(['Week',\"item\"])[\"sales\"].transform(\"sum\") # total sales of that item  for all stores\n",
    "#df[\"store-week-sum\"] = df.groupby(['Week',\"store\"])[\"sales\"].transform(\"sum\") # total sales of that store  for all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Is_month_end', 'Is_month_start','Is_quarter_end',\n",
    "                 'Is_quarter_start','Is_year_end','Is_year_start', 'Elapsed'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df[\"item-week_shifted-90\"] = df.groupby(['Week',\"item\"])[\"sales\"].transform(lambda x:x.shift(12).sum()) # shifted total sales for that item 12 weeks (3 months) ago\n",
    "# df[\"store-week_shifted-90\"] = df.groupby(['Week',\"store\"])[\"sales\"].transform(lambda x:x.shift(12).sum()) # shifted total sales for that store 12 weeks (3 months) ago\n",
    "# df[\"item-week_shifted-90\"] = df.groupby(['Week',\"item\"])[\"sales\"].transform(lambda x:x.shift(12).mean()) # shifted mean sales for that item 12 weeks (3 months) ago\n",
    "# df[\"store-week_shifted-90\"] = df.groupby(['Week',\"store\"])[\"sales\"].transform(lambda x:x.shift(12).mean()) # shifted mean sales for that store 12 weeks (3 months) ago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Split Training-Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.shape, sales.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# closest same period (diff year) as test set\n",
    "X_valid = train.loc[(train.Year==2017) & ((train.Month==1) | (train.Month==2) | (train.Month==3))].copy() \n",
    "y_valid = sales[X_valid.index].copy()\n",
    "\n",
    "X_train = train.drop(X_valid.index).copy()\n",
    "y_train = sales.drop(X_valid.index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## With Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(n_estimators=200, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions_train = rf.predict(X_train)\n",
    "print_scores(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions_valid = rf.predict(X_valid)\n",
    "print_scores(predictions_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_preds(predictions_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## All In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(n_estimators=200, n_jobs=-1)\n",
    "rf.fit(train, sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f'{PATH}test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission['sales'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "csv_fn = f'{PATH}tmp/RF_v3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission[['sales']].to_csv(csv_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.barh(X_train.columns, rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With extra feature:\n",
    "    \n",
    "RMSE: 6.922376650801049\n",
    "MAE: 5.378433555555555\n",
    "SMAPE: 12.689213546757514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
