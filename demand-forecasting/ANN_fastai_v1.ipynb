{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "\n",
    "PATH = \"data/demand-forecasting/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(((y_pred-y_true)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_pred,y_true):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.nanmean(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{PATH}train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv(f'{PATH}test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(train.head(1))\n",
    "display(train.tail(1))\n",
    "\n",
    "display(test.head(1))\n",
    "display(test.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# DataFrameSummary(train).summary()\n",
    "# DataFrameSummary(test).summary()\n",
    "\n",
    "# train.info()\n",
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train[train.sales==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train[train.sales<train.sales.quantile(0.01)]), len(train[train.sales<train.sales.quantile(0.001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train[train.sales>train.sales.quantile(0.99)]), len(train[train.sales>train.sales.quantile(0.999)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# exclude certain rows\n",
    "# train = train[train.sales!=0]\n",
    "\n",
    "#train = train[(train.sales>train.sales.quantile(q=0.001)) & (train.sales<train.sales.quantile(q=0.999))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train.reset_index(drop=True,inplace=True)\n",
    "# test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.to_feather(f'{PATH}train_raw')\n",
    "test.to_feather(f'{PATH}test_raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather(f'{PATH}train_raw')\n",
    "test = pd.read_feather(f'{PATH}test_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_all_data = 0\n",
    "validation_data_mode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['store', 'item', 'Month', 'Week', 'Day','Dayofweek', 'Dayofyear']\n",
    "contin_vars = ['Year', 'Elapsed'] \n",
    "\n",
    "# Elapsed = Unix Timestamp ( 0 = 1 Jan 1970 12.00am and can be negative)\n",
    "# Discared date categorical variables\n",
    "# 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start','Is_year_end', 'Is_year_start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(train, \"date\", drop=False)\n",
    "add_datepart(test, \"date\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorg train and test dataset\n",
    "dependent = 'sales'\n",
    "train = train[cat_vars+contin_vars+[dependent, 'date']].copy()\n",
    "\n",
    "test[dependent] = 0 # broadcast zero for 'Sales' dummy col\n",
    "test = test[cat_vars+contin_vars+[dependent, 'date', 'id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in cat_vars: train[v] = train[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cats(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in contin_vars:\n",
    "    train[v] = train[v].fillna(0).astype('float32')\n",
    "    test[v] = test[v].fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_all_data == 0:\n",
    "    # Get a sample m from all training data\n",
    "    m = 200000\n",
    "    idxs = get_cv_idxs(n, val_pct=m/n) # get random sample by index, nothing to do with validation\n",
    "    train_samp = train.iloc[idxs].set_index(\"date\")\n",
    "    sample_size = len(train_samp)\n",
    "    sample_size\n",
    "elif use_all_data == 1:\n",
    "    # Set sample size equal to total data to use all data\n",
    "    sample_size = n\n",
    "    train_samp = train.set_index(\"date\")\n",
    "else:\n",
    "    pass\n",
    "    #raise Exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 913000, 45000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samp), len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, y_train, nas, mapper = proc_df(train_samp, 'sales', do_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index(\"date\")\n",
    "\n",
    "df_test, _, nas, mapper = proc_df(test, 'sales', do_scale=True, skip_flds=['id'],\n",
    "                                  mapper=mapper, na_dict=nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation_data_mode == 0:\n",
    "    val_idx = [0]\n",
    "elif validation_data_mode == 1:\n",
    "    val_idx = np.flatnonzero(\n",
    "        (df_train.index>=datetime.datetime(2017,10,1)) & (df_train.index<=datetime.datetime(2017,12,31)))\n",
    "elif validation_data_mode == 2:\n",
    "    val_idx = np.flatnonzero(\n",
    "        (df_train.index>=datetime.datetime(2017,1,1)) & (df_train.index<=datetime.datetime(2017,3,31)))\n",
    "else:\n",
    "    raise ValueError(\"Invalid validation_data_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 10131, 45000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(val_idx), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return ColumnarModelData.from_data_frame(PATH, val_idx, \n",
    "                                             df_train, y_train.astype(np.float32), \n",
    "                                             cat_flds=cat_vars, bs=128,\n",
    "                                             test_df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embedding Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sz = [(c, len(train_samp[c].cat.categories)+1) for c in cat_vars]\n",
    "# cat_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "# emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, # size of embeddings\n",
    "                   len(df_train.columns)-len(cat_vars), # size of continuous vars\n",
    "                   0.04, # embedding droput\n",
    "                   1, # number of output\n",
    "                   [1024,512], # fully connected layer hidden units\n",
    "                   [0.001,0.01]) # fully connected layers droput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b93813efc1481c931f3501c4428715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████▌                          | 906/1484 [00:08<00:05, 103.64it/s, loss=281]\n",
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "m.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.sched.plot(n_skip=0,n_skip_end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fit on Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.fit(lr, 3, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.fit(lr, 5, cycle_len=1, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.fit(lr, 2, cycle_len=4, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.save('md_sample_trained_v1_no_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.load('md_sample_trained_v1_no_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fit on All Data (with/without validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md_all_3mth_val = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.set_data(md_all_3mth_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.fit(lr, 3, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.fit(lr, 3, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.save('md_all_3mth_val_trained_v1_no_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.load('md_all_3mth_val_trained_v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = get_data()\n",
    "m = md.get_learner(emb_szs, # size of embeddings\n",
    "                   len(df_train.columns)-len(cat_vars), # size of continuous vars\n",
    "                   0.04, # embedding droput\n",
    "                   1, # number of output\n",
    "                   [1024,512], # fully connected layer hidden units\n",
    "                   [0.001,0.01]) # fully connected layers droput\n",
    "lr=1e-2\n",
    "m.fit(lr, 10, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7778bd1b65418a97bcb7c8b688964e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
      "    0      55.53449   63.057454  12.769399  7.931656  \n",
      "    1      53.819436  58.445046  12.416929  7.637124                                                                   \n",
      "    2      54.034881  57.202748  12.265239  7.555631                                                                   \n",
      "    3      54.504813  58.386817  12.33119   7.632342                                                                   \n",
      "    4      54.105913  60.075042  12.454708  7.741833                                                                   \n",
      "    5      53.74105   57.481343  12.272604  7.573663                                                                   \n",
      "    6      52.315792  57.412209  12.311432  7.569022                                                                   \n",
      "    7      51.295641  57.634789  12.28423   7.583726                                                                   \n",
      "    8      52.061624  57.989182  12.351326  7.606962                                                                   \n",
      "    9      52.927322  59.374474  12.447874  7.696541                                                                   \n",
      "    10     52.478668  58.461435  12.422515  7.639171                                                                   \n",
      "    11     50.713551  58.053461  12.337526  7.611457                                                                   \n",
      "    12     52.009069  58.429359  12.436555  7.63626                                                                    \n",
      "    13     51.922292  58.881553  12.431735  7.665048                                                                   \n",
      "    14     52.335762  59.098119  12.426469  7.679345                                                                   \n",
      "    15     49.727708  61.500149  12.674865  7.833346                                                                   \n",
      "Round 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2cb59075734af1b8548b6c9a53025f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
      "    0      54.577802  59.598971  12.441973  7.712246  \n",
      "    1      55.496369  57.233959  12.236618  7.55785                                                                    \n",
      "    2      52.903601  57.280213  12.297394  7.560898                                                                   \n",
      "    3      54.918977  60.082602  12.485374  7.743217                                                                   \n",
      "    4      54.673272  57.271634  12.252703  7.560084                                                                   \n",
      "    5      53.514122  59.142554  12.355695  7.681612                                                                   \n",
      "    6      52.683808  59.475637  12.461267  7.703757                                                                   \n",
      "    7      53.317477  57.168969  12.226239  7.553378                                                                   \n",
      "    8      54.506449  57.672484  12.300863  7.586671                                                                   \n",
      "    9      52.527303  57.587786  12.275863  7.581177                                                                   \n",
      "    10     52.56498   57.868711  12.30399   7.598707                                                                   \n",
      "    11     53.469311  58.729437  12.373238  7.655416                                                                   \n",
      "    12     52.703122  57.725432  12.313971  7.589886                                                                   \n",
      " 55%|█████████████████████████████████████▏                             | 1852/3339 [00:25<00:20, 72.79it/s, loss=51.9]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-0b19c4a0692d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msmape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Projects\\deep-learning\\kaggle\\demand-forecasting\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\deep-learning\\kaggle\\demand-forecasting\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[1;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\deep-learning\\kaggle\\demand-forecasting\\fastai\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\deep-learning\\kaggle\\demand-forecasting\\fastai\\model.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, xs, y, epoch)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mcopy_fp32_to_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    m = 450_000\n",
    "    idxs = get_cv_idxs(n, val_pct=m/n) # get random sample by index, nothing to do with validation\n",
    "    train_samp = train.iloc[idxs].set_index(\"date\")\n",
    "    df_train, y_train, nas, mapper = proc_df(train_samp, 'sales', do_scale=True)\n",
    "    \n",
    "    val_idx = np.flatnonzero(\n",
    "        (df_train.index>=datetime.datetime(2017,10,1)) & (df_train.index<=datetime.datetime(2017,12,31)))\n",
    "    \n",
    "    lr=5e-4\n",
    "    print(f\"Round {i+1}\")\n",
    "\n",
    "    md = get_data()\n",
    "    m = md.get_learner(emb_szs, # size of embeddings\n",
    "                       len(df_train.columns)-len(cat_vars), # size of continuous vars\n",
    "                       0.001, # embedding droput\n",
    "                       1, # number of output\n",
    "                       [1024,512], # fully connected layer hidden units\n",
    "                       [0.001,0.001]) # fully connected layers droput\n",
    "\n",
    "\n",
    "    m.fit(lr, 16, metrics=[smape, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "59~60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_test = m.predict(True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With full data\n",
    "m = md.get_learner(emb_szs,\n",
    "                   len(df_train.columns)-len(cat_vars), \n",
    "                   0.04,\n",
    "                   1, \n",
    "                   [1024,512], \n",
    "                   [0.001,0.01]) \n",
    "                   \n",
    "lr = 1e-5\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      62.122926  57.591857  12.385114  7.401448  \n",
    "    1      61.770513  57.220312  12.342788  7.379273                                                                   \n",
    "    2      61.695171  57.179892  12.33951   7.375439                                                                   \n",
    "    3      60.180414  57.126639  12.33406   7.372616                                                                   \n",
    "    4      59.085921  56.938853  12.309912  7.360633                                                                   \n",
    "    5      60.065405  56.821083  12.30453   7.352635                                                                   \n",
    "    6      59.744112  56.797369  12.298577  7.351344                                                                   \n",
    "    7      60.797821  56.777386  12.298522  7.350059   \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      62.660462  58.276493  12.59405   7.451086  \n",
    "    1      61.777216  57.902509  12.522098  7.42487                                                                    \n",
    "    2      60.872966  57.852778  12.526644  7.422848                                                                   \n",
    "    3      60.49795   57.837048  12.538474  7.423138                                                                   \n",
    "    4      60.086843  57.733541  12.530525  7.417375                                                                   \n",
    "    5      59.325197  57.471404  12.467384  7.398117                                                                   \n",
    "    6      58.994807  57.389352  12.461741  7.393522                                                                   \n",
    "    7      58.686376  57.400014  12.469684  7.394812     \n",
    "\n",
    "\n",
    "lr = 5e-4     \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      54.674476  56.978864  12.285486  7.361971  \n",
    "    1      52.767114  56.746945  12.268337  7.343473                                                                   \n",
    "    2      53.913669  56.425869  12.260626  7.325097                                                                   \n",
    "    3      51.819611  56.393649  12.248555  7.322085                                                                   \n",
    "    4      54.754531  57.309219  12.440643  7.389318                                                                   \n",
    "    5      53.898975  56.70404   12.281197  7.341856                                                                   \n",
    "    6      52.361032  56.783839  12.326413  7.349774                                                                   \n",
    "    7      51.409112  56.428446  12.256523  7.324917    \n",
    "                   \n",
    "lr = 1e-4\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.266375  56.712695  12.281181  7.343027  \n",
    "    1      55.720272  57.201784  12.277717  7.372701                                                                   \n",
    "    2      53.981764  56.665257  12.275264  7.339986                                                                   \n",
    "    3      53.033967  56.606209  12.262039  7.336532                                                                   \n",
    "    4      53.99906   56.972103  12.287485  7.357748                                                                   \n",
    "    5      54.297139  57.269981  12.293807  7.378626                                                                   \n",
    "    6      53.315673  56.488667  12.258805  7.329549                                                                   \n",
    "    7      53.231557  56.597124  12.25999   7.335905 \n",
    "    \n",
    "lr = 5e-3\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      56.401217  56.756283  12.321561  7.351762  \n",
    "    1      54.355544  56.569624  12.317566  7.339634                                                                   \n",
    "    2      53.322395  56.200047  12.251931  7.312602                                                                   \n",
    "    3      54.187818  56.189586  12.232301  7.311199                                                                   \n",
    "    4      56.91844   58.298584  12.462768  7.445894                                                                   \n",
    "    5      55.92635   57.250384  12.326662  7.377961                                                                   \n",
    "    6      54.252245  57.204502  12.306426  7.368984                                                                   \n",
    "    7      54.036137  56.120614  12.21986   7.306776    \n",
    "    \n",
    "lr = 1e-3\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      59.534096  59.030127  12.35334   7.674208  \n",
    "    1      59.084759  58.464777  12.241951  7.63775                                                                    \n",
    "    2      58.888075  58.498873  12.258914  7.639932                                                                   \n",
    "    3      57.84943   58.456811  12.245071  7.63708                                                                    \n",
    "    4      58.866993  59.02645   12.255151  7.674182                                                                   \n",
    "    5      57.74203   58.942923  12.261465  7.669117                                                                   \n",
    "    6      56.234312  58.576643  12.221763  7.645227                                                                   \n",
    "    7      57.121077  58.564269  12.219188  7.644431 \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      53.669664  57.051262  12.266915  7.360848  \n",
    "    1      53.958698  58.539237  12.312301  7.441045                                                                   \n",
    "    2      52.701254  56.331281  12.234603  7.318462                                                                   \n",
    "    3      52.633648  56.367355  12.217106  7.320063                                                                   \n",
    "    4      52.482797  57.147474  12.273487  7.368852                                                                   \n",
    "    5      53.619903  56.491378  12.255165  7.333597                                                                   \n",
    "    6      51.985735  56.898776  12.247102  7.350162                                                                   \n",
    "    7      52.818756  56.610458  12.229606  7.333681     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test2['sales'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "csv_fn=f'{PATH}tmp/ann_v1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test2[['id','sales']].to_csv(csv_fn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Variations of Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Version 1 (Using 'Year' as continuous variable, removed 'Elapsed')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- lr = 3e-4\n",
    "- cat_vars = ['store', 'item', 'Month', 'Week', 'Day','Dayofweek', 'Dayofyear']\n",
    "- contin_vars = ['Year']\n",
    "- 200,000 sample, then full data with 2 months as validation\n",
    "\n",
    "Sample\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      67.229439  56.98025   14.784727  7.540044  \n",
    "    1      62.550226  49.120328  13.69981   7.000307                                                                   \n",
    "    2      60.951366  46.194498  13.275509  6.787601 \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      57.53622   46.689523  13.381637  6.824401  \n",
    "    1      56.454038  46.096327  13.306613  6.780591                                                                   \n",
    "    2      57.407762  46.07425   13.288407  6.778722                                                                   \n",
    "    3      57.308635  46.238925  13.334494  6.791201                                                                   \n",
    "    4      56.197855  46.857823  13.422821  6.836513  \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      58.072366  49.325639  13.684166  7.01509   \n",
    "    1      57.09147   46.157076  13.308137  6.784514                                                                   \n",
    "    2      54.243643  46.91151   13.394555  6.840287                                                                   \n",
    "    3      54.842126  46.607488  13.377399  6.817889                                                                   \n",
    "    4      56.904505  49.955257  13.693943  7.059816                                                                   \n",
    "    5      54.723685  47.89583   13.512489  6.911717                                                                   \n",
    "    6      55.240703  46.891768  13.405679  6.838851                                                                   \n",
    "    7      52.89749   46.696623  13.385203  6.824682    \n",
    "    \n",
    "All\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      56.632833  47.505602  13.452764  6.732215  \n",
    "    1      54.777428  49.090793  13.668107  6.831906                                                                   \n",
    "    2      54.454943  47.584162  13.54906   6.746982\n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      53.599329  48.221338  13.620007  6.781455  \n",
    "    1      54.602614  49.565631  13.684969  6.863176                                                                   \n",
    "    2      53.17853   48.665303  13.607777  6.805671     "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 200000 sample, then full data. Both without validation\n",
    "\n",
    "FULL SAMPLE\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      67.226694  9.642811   18.760071  3.105288  \n",
    "    1      61.984205  13.62572   21.9125    3.691303                                                                   \n",
    "    2      59.50212   2.058616   9.128662   1.434788   \n",
    "\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      59.038505  2.645462   10.285604  1.626488  \n",
    "    1      57.776065  5.708579   14.753428  2.389263                                                                   \n",
    "    2      57.276353  3.875511   12.316021  1.968632                                                                   \n",
    "    3      56.80017   4.102269   12.648745  2.025406                                                                   \n",
    "    4      55.658362  4.297068   12.926394  2.072937 \n",
    " \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      59.181086  1.062226   6.642746   1.030643  \n",
    "    1      55.393255  3.714719   12.07341   1.927361                                                                   \n",
    "    2      56.531146  5.576627   14.594436  2.361488                                                                   \n",
    "    3      55.409476  4.033103   12.54838   2.008259                                                                   \n",
    "    4      56.418702  5.539943   14.549853  2.353708                                                                   \n",
    "    5      55.629441  6.966576   16.173244  2.639427                                                                   \n",
    "    6      55.465383  5.388489   14.363971  2.321312                                                                   \n",
    "    7      52.578834  6.007028   15.105419  2.450924        \n",
    "\n",
    "    \n",
    "FULL ALL\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.107064  9.107539   26.262753  3.01787   \n",
    "    1      55.100275  8.756807   25.686514  2.95919                                                                    \n",
    "    2      56.099405  9.935395   27.591497  3.152046   \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      54.166042  5.696932   20.216042  2.386825  \n",
    "    1      53.798681  9.67555    27.178944  3.110555                                                                   \n",
    "    2      54.171071  9.987793   27.674212  3.160347\n",
    "\n",
    "    \n",
    "KAGGLE SCORE: 14.15551 (PUBLIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Version 2 (Using 'Elapsed' as continuous variable, 'Year' as categorical)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- lr = 3e-4\n",
    "- cat_vars = ['store', 'item', 'Year', 'Month', 'Week', 'Day','Dayofweek', 'Dayofyear']\n",
    "- contin_vars = ['Elapsed'] \n",
    "- 200000 sample, then full data with 2 months as validation\n",
    "\n",
    "Sample\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      64.695786  49.548196  13.754997  7.030174  \n",
    "    1      62.80054   50.460138  13.625147  7.095592                                                                   \n",
    "    2      61.544155  46.775959  13.402724  6.8313     \n",
    "\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      59.383063  46.50231   13.332739  6.811977  \n",
    "    1      56.420043  46.372553  13.319377  6.802296                                                                   \n",
    "    2      56.67704   46.452721  13.334541  6.808238                                                                   \n",
    "    3      55.906044  46.28618   13.334883  6.795739                                                                   \n",
    "    4      57.282269  47.100555  13.456188  6.855513 \n",
    "  \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      57.473112  46.639563  13.400299  6.82112   \n",
    "    1      57.292216  50.125949  13.697948  7.07182                                                                    \n",
    "    2      56.21177   47.128835  13.432553  6.857345                                                                   \n",
    "    3      54.842316  46.875517  13.423521  6.8388                                                                     \n",
    "    4      55.285312  47.192277  13.424182  6.861348                                                                   \n",
    "    5      54.746742  47.80413   13.532646  6.906469                                                                   \n",
    "    6      53.535683  46.926237  13.429708  6.842317                                                                   \n",
    "    7      53.289487  47.404254  13.494919  6.877302                                                                   \n",
    "\n",
    "All\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.81306   47.026534  13.357312  6.696208  \n",
    "    1      55.055634  48.937868  13.672912  6.832806                                                                   \n",
    "    2      55.338555  49.045251  13.506786  6.812673   \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      54.74143   46.982532  13.364016  6.695584  \n",
    "    1      55.13812   47.191436  13.392557  6.709293                                                                   \n",
    "    2      54.009995  46.43918   13.36782   6.663434 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 200000 sample, then full data. Both without validation\n",
    "\n",
    "FULL SAMPLE\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      64.286743  7.786777   17.02006   2.79048   \n",
    "    1      59.816039  1.915194   8.819204   1.383905                                                                   \n",
    "    2      59.661596  1.550915   7.971473   1.245358   \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      58.76797   1.481412   7.79785    1.217133  \n",
    "    1      58.191591  2.177951   9.377291   1.475788                                                                   \n",
    "    2      58.607204  2.741376   10.460736  1.65571                                                                    \n",
    "    3      56.044953  3.073679   11.042613  1.753191                                                                   \n",
    "    4      55.986701  3.231454   11.30666   1.797625 \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.067492  6.117265   15.23288   2.47331   \n",
    "    1      54.930538  4.189885   12.774524  2.046921                                                                   \n",
    "    2      54.292985  1.434167   7.67731    1.197567                                                                   \n",
    "    3      53.536259  2.19298    9.40807    1.480871                                                                   \n",
    "    4      56.231182  3.208933   11.269414  1.791349                                                                   \n",
    "    5      54.944305  1.203845   7.056575   1.097198                                                                   \n",
    "    6      53.75232   1.689175   8.304766   1.299683                                                                   \n",
    "    7      52.360709  1.458569   7.739831   1.207712       \n",
    "    \n",
    "FULL ALL\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.970664  7.38027    23.335707  2.716665  \n",
    "    1      56.049877  3.647874   15.856671  1.909941                                                                   \n",
    "    2      53.524416  4.533147   17.838631  2.129119  \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      53.09611   5.27652    19.382139  2.297068  \n",
    "    1      53.444876  4.622387   18.029112  2.149974                                                                   \n",
    "    2      53.494227  7.20145    23.01853   2.683552 \n",
    "    \n",
    "KAGGLE SCORE: 18.02563 ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Version 3 (Using 'Year' and 'Elapsed' as continuous variable)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- lr = 3e-4\n",
    "- cat_vars = ['store', 'item', 'Month', 'Week', 'Day','Dayofweek', 'Dayofyear']\n",
    "- contin_vars = ['Elapsed', 'Year'] \n",
    "- 200000 sample, then full data with 2 months as validation\n",
    "\n",
    "Sample\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      67.703145  51.727609  13.972338  7.183373  \n",
    "    1      61.319969  46.75682   13.350529  6.829372                                                                   \n",
    "    2      60.221945  46.709159  13.435191  6.826349 \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      57.785871  46.183099  13.351803  6.787656  \n",
    "    1      57.706258  46.369153  13.36976   6.801273                                                                   \n",
    "    2      56.420103  46.398415  13.382423  6.802779                                                                   \n",
    "    3      56.861633  46.528526  13.395238  6.81239                                                                    \n",
    "    4      55.960248  46.636365  13.400374  6.820301   \n",
    "  \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      57.904529  47.617071  13.533353  6.892407  \n",
    "    1      56.070068  47.197308  13.515368  6.860859                                                                   \n",
    "    2      54.150258  46.873714  13.470309  6.83722                                                                    \n",
    "    3      54.402841  47.095221  13.477276  6.853496                                                                   \n",
    "    4      55.295993  46.936995  13.522     6.841844                                                                   \n",
    "    5      54.211802  48.767262  13.55866   6.973449                                                                   \n",
    "    6      53.812386  47.121991  13.446988  6.854854                                                                   \n",
    "    7      53.135117  47.179762  13.484785  6.859134  \n",
    " \n",
    "All\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      56.45778   47.300013  13.485232  6.725529  \n",
    "    1      54.980859  48.12625   13.446304  6.76557                                                                    \n",
    "    2      55.320116  46.728999  13.338278  6.679828         \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.035153  48.551403  13.648818  6.806748  \n",
    "    1      53.321489  48.160676  13.525645  6.772811                                                                   \n",
    "    2      54.353087  46.822664  13.410246  6.691704        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- 200000 sample, then full data. Both without validation\n",
    "\n",
    "FULL SAMPLE\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      66.735611  3.627705   11.93966   1.904654  \n",
    "    1      60.111593  0.459879   4.625515   0.678143                                                                   \n",
    "    2      60.558466  0.52856    4.73213    0.727021      \n",
    "\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      58.245724  0.685936   5.373083   0.828213  \n",
    "    1      56.878737  0.514758   4.671391   0.717466                                                                   \n",
    "    2      55.217455  0.904706   6.146202   0.95116                                                                    \n",
    "    3      56.619162  0.717477   5.491873   0.84704                                                                    \n",
    "    4      57.069598  0.778213   5.713097   0.882164   \n",
    "\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      56.038079  0.341301   3.820334   0.584209  \n",
    "    1      55.201964  0.154654   2.587817   0.393261                                                                   \n",
    "    2      54.950509  1.388501   7.55875    1.178347                                                                   \n",
    "    3      54.509983  0.749362   5.609191   0.865657                                                                   \n",
    "    4      56.633989  0.624189   5.131892   0.790056                                                                   \n",
    "    5      54.87274   0.562414   4.877686   0.749943                                                                   \n",
    "    6      55.045556  0.84357    5.941181   0.918461                                                                   \n",
    "    7      53.314921  0.517374   4.682966   0.719287\n",
    "    \n",
    "FULL ALL\n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      55.115527  6.41149    21.579189  2.532092  \n",
    "    1      53.091431  9.224439   26.452986  3.037176                                                                   \n",
    "    2      53.503577  8.22252    24.791897  2.867494   \n",
    "    \n",
    "epoch      trn_loss   val_loss   smape      rmse                                                                       \n",
    "    0      53.378535  10.617835  28.656883  3.258502  \n",
    "    1      53.305781  4.998852   18.816643  2.235811                                                                   \n",
    "    2      52.946706  4.663404   18.116154  2.159491   \n",
    "    \n",
    "KAGGLE SCORE: 14.10082 (Public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prediction on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.load('md_all_3mth_val_trained_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_val = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_val = m.predict(False)  # predict on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# stick the prediction to copy of test data, and then offset by 12 months \n",
    "# because that's how our validation data is defined (2017-01-01 to 2017-03-31)\n",
    "test_val['sales'] = pred_val\n",
    "test_val['date'] = test_val['date'] - pd.DateOffset(months=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_val.drop('id',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,120)) #(width,height)\n",
    "plt.title(\"Store'sale pattern\")\n",
    "plt.grid()\n",
    "for store in range(1): #set range to 10 to show all 10 stores\n",
    "    plt.subplot(10,1,store+1) \n",
    "    performance_of_store = pd.pivot_table(train[(train.store==(store+1)) & (train.date.dt.year>2015)],\n",
    "                                          index=['date'],\n",
    "                                          columns=['store',],\n",
    "                                          values='sales',\n",
    "                                          aggfunc=np.sum)\n",
    "    plt.plot(performance_of_store,color='b',label=\"Store-\"+str(store+1)+\" Actual Total sales\")\n",
    "    \n",
    "    performance_of_store = pd.pivot_table(test_val[test_val.store==(store+1)],\n",
    "                                          index=['date'],\n",
    "                                          columns=['store',],\n",
    "                                          values='sales',\n",
    "                                          aggfunc=np.sum)\n",
    "    plt.plot(performance_of_store,color='r',label=\"Store-\"+str(store+1)+\" Predicted total sales\")\n",
    "    plt.legend(loc='upper left', shadow=True, prop={'size': 24})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,150)) #(width,height)\n",
    "plt.title(\"Store'sale pattern\")\n",
    "plt.grid()\n",
    "for store in range(1): #set range to 10 to show all 10 stores\n",
    "    plt.subplot(10,1,store+1) \n",
    "    performance_of_store = pd.pivot_table(train[(train.store==(store+1)) \n",
    "                                                & (((train.date.dt.year==2017) & (train.date.dt.month<5))\n",
    "                                                | ((train.date.dt.year==2016) & (train.date.dt.month>11)))],\n",
    "                                          index=['date'],\n",
    "                                          columns=['store',],\n",
    "                                          values='sales',\n",
    "                                          aggfunc=np.sum)\n",
    "    plt.plot(performance_of_store,color='b',label=\"Store-\"+str(store+1)+\" Actual Total sales\")\n",
    "    \n",
    "    performance_of_store = pd.pivot_table(test_val[test_val.store==(store+1)],\n",
    "                                          index=['date'],\n",
    "                                          columns=['store',],\n",
    "                                          values='sales',\n",
    "                                          aggfunc=np.sum)\n",
    "    plt.plot(performance_of_store,color='r',label=\"Store-\"+str(store+1)+\" Predicted total sales\")\n",
    "    plt.grid()\n",
    "    plt.legend(loc='upper left', shadow=True, prop={'size': 24})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m.load('md_all_3mth_val_trained_v3_no_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_test = m.predict(True) # predict on test data# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_pred = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_pred['sales'] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_pred.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,120)) #(width,height)\n",
    "plt.title(\"Store'sale pattern\")\n",
    "plt.grid()\n",
    "for store in range(10):\n",
    "    plt.subplot(10,1,store+1) \n",
    "    performance_of_store = pd.pivot_table(train[train.store==(store+1)],index=['date'],\n",
    "                                          columns=['store',],values='sales',aggfunc=np.sum)\n",
    "    plt.plot(performance_of_store,color='b',label=\"Store-\"+str(store+1)+\" Actual Total sales\")\n",
    "    \n",
    "    performance_of_store = pd.pivot_table(test_pred[test_pred.store==(store+1)],index=['date'],\n",
    "                                          columns=['store',],values='sales',aggfunc=np.sum)\n",
    "    plt.plot(performance_of_store,color='r',label=\"Store-\"+str(store+1)+\" Predicted total sales\")\n",
    "    plt.legend(loc='upper left', shadow=True, prop={'size': 24})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
