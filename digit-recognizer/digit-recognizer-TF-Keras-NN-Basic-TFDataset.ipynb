{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qWT31nsxURdJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_orig = np.genfromtxt('data/MNIST/train.csv', delimiter=',', skip_header=1)\n",
    "test_images_orig = np.genfromtxt('data/MNIST/test.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images_orig.shape, test_images_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels,train_images = train_images_orig[:,0].copy(), train_images_orig[:,1:].copy() # label, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_images_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,), (28000, 784))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images.shape, train_labels.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5eDlt-AnVafg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28000, 784)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "IMAGE_SIZE_UNSTACKED = train_images.shape[1]\n",
    "\n",
    "TRAINING_SIZE, TEST_SIZE, IMAGE_SIZE_UNSTACKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YNi4TNvlVcIB"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding on output/label\n",
    "NUM_DIGITS = 10\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_DIGITS)\n",
    "train_labels = train_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(IMAGE_SIZE_UNSTACKED,)))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iHaND5a6Vc-B"
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow optimizer, rather than using the Keras version\n",
    "# This is currently necessary when working in eager mode\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "# We will now compile and print out a summary of our model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8jpqP9JYVgxM"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# Because tf.data may work with potentially **large** collections of data\n",
    "# we do not shuffle the entire dataset by default\n",
    "# Instead, we maintain a buffer of SHUFFLE_SIZE elements\n",
    "# and sample from there.\n",
    "SHUFFLE_SIZE = 10000 \n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jvDEbM1DVigY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\t Loss: 0.128158\tAccuracy: 0.937500\n",
      "Epoch #2\t Loss: 0.011408\tAccuracy: 1.000000\n",
      "Epoch #3\t Loss: 0.004916\tAccuracy: 1.000000\n",
      "Epoch #4\t Loss: 0.120130\tAccuracy: 0.937500\n",
      "Epoch #5\t Loss: 0.000864\tAccuracy: 1.000000\n",
      "Epoch #6\t Loss: 0.100982\tAccuracy: 0.937500\n",
      "Epoch #7\t Loss: 0.000141\tAccuracy: 1.000000\n",
      "Epoch #8\t Loss: 0.000226\tAccuracy: 1.000000\n",
      "Epoch #9\t Loss: 0.000014\tAccuracy: 1.000000\n",
      "Epoch #10\t Loss: 0.000004\tAccuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Instead of using model.fit, we use model.train_on_batch\n",
    "# as we iterate over our dataset\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in dataset:\n",
    "        train_loss, train_accuracy = model.train_on_batch(images, labels)\n",
    "\n",
    "    # Here you can gather any metrics or adjust your training parameters\n",
    "    print('Epoch #%d\\t Loss: %.6f\\tAccuracy: %.6f' % (epoch + 1, train_loss, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('submissions', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    \"models/digit-recognizer-TF-Keras-NN-Basic3\",\n",
    "    include_optimizer=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = tf.keras.models.load_model(\"model/digit-recognizer-TF-Keras-NN-Basic3\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = md.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = tf.argmax(prediction,axis=1)\n",
    "image_id = np.array(np.arange(1,TEST_SIZE+1))\n",
    "result = np.column_stack((image_id, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"submissions/digit-recognizer-TF-Keras-NN-Basic3.csv\", result, fmt=('%d,%d'), delimiter=\",\", \\\n",
    "           header=\"ImageId,Label\",comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Digit Recognizer\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c digit-recognizer -f output/digit-recognizer-TF-Keras-NN-Basic3.csv -m \"TF/Keras NN Basic 3 with 10 epochs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Kaggle Scores:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic\n",
    "Score: 0.97614 (10 epochs)\n",
    "- model = tf.keras.Sequential()\n",
    "- model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(IMAGE_SIZE_UNSTACKED,)))\n",
    "- model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic2\n",
    "Score: 0.97971 (20 epochs)\n",
    "    \n",
    "- model = tf.keras.Sequential()\n",
    "- model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(IMAGE_SIZE_UNSTACKED,)))\n",
    "- model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu, input_shape=(IMAGE_SIZE_UNSTACKED,)))\n",
    "- model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic 3 Score: 0.97671(10 epochs)\n",
    "    \n",
    "- model = tf.keras.Sequential()\n",
    "- model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(IMAGE_SIZE_UNSTACKED,)))\n",
    "- model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu, input_shape=(IMAGE_SIZE_UNSTACKED,)))\n",
    "- model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "5-conv-draft.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
