{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qWT31nsxURdJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('model', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('data/MNIST/train.csv', delimiter=',', skip_header=1)\n",
    "test_data = np.genfromtxt('data/MNIST/test.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train =  train_data[:,1:].copy(), train_data[:,0].copy() # features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,), (28000, 784))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and convert the train images and add channels\n",
    "X_train /= 255\n",
    "X_train = X_train.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Scale and convert the train images and add channels\n",
    "X_test /= 255\n",
    "X_test = X_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 28, 28, 1), (42000, 10), (28000, 28, 28, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Plot images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=36, kernel_size=(5, 5), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation=tf.nn.relu, input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iHaND5a6Vc-B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 184,586\n",
      "Trainable params: 184,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Keras vs TF optimizer\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb1 = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "       tf.keras.callbacks.ModelCheckpoint(filepath='model/best_model_val.h5', \n",
    "                                                monitor='val_loss',\n",
    "                                                save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/20\n",
      "31500/31500 [==============================] - 6s 198us/step - loss: 0.3845 - acc: 0.8841 - val_loss: 0.4436 - val_acc: 0.8714\n",
      "Epoch 2/20\n",
      "31500/31500 [==============================] - 4s 112us/step - loss: 0.0961 - acc: 0.9708 - val_loss: 0.0978 - val_acc: 0.9695\n",
      "Epoch 3/20\n",
      "31500/31500 [==============================] - 4s 113us/step - loss: 0.0588 - acc: 0.9818 - val_loss: 0.0476 - val_acc: 0.9856\n",
      "Epoch 4/20\n",
      "31500/31500 [==============================] - 4s 112us/step - loss: 0.0399 - acc: 0.9879 - val_loss: 0.0904 - val_acc: 0.9731\n",
      "Epoch 5/20\n",
      "31500/31500 [==============================] - 4s 113us/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0395 - val_acc: 0.9876\n",
      "Epoch 6/20\n",
      "31500/31500 [==============================] - 4s 113us/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0505 - val_acc: 0.9851\n",
      "Epoch 7/20\n",
      "31500/31500 [==============================] - 4s 113us/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0798 - val_acc: 0.9768\n",
      "Epoch 8/20\n",
      "31500/31500 [==============================] - 4s 114us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0425 - val_acc: 0.9876\n",
      "Epoch 9/20\n",
      "31500/31500 [==============================] - 4s 115us/step - loss: 0.0121 - acc: 0.9962 - val_loss: 0.0393 - val_acc: 0.9894\n",
      "Epoch 10/20\n",
      "31500/31500 [==============================] - 4s 117us/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.0502 - val_acc: 0.9873\n",
      "Epoch 11/20\n",
      "31500/31500 [==============================] - 4s 122us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0512 - val_acc: 0.9871\n",
      "Epoch 12/20\n",
      "31500/31500 [==============================] - 4s 126us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0490 - val_acc: 0.9880\n",
      "Epoch 13/20\n",
      "31500/31500 [==============================] - 4s 123us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0518 - val_acc: 0.9891\n",
      "Epoch 14/20\n",
      "31500/31500 [==============================] - 4s 121us/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0548 - val_acc: 0.9899\n",
      "Epoch 15/20\n",
      "31500/31500 [==============================] - 4s 121us/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0528 - val_acc: 0.9890\n",
      "Epoch 16/20\n",
      "31500/31500 [==============================] - 4s 121us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0531 - val_acc: 0.9879\n",
      "Epoch 17/20\n",
      "31500/31500 [==============================] - 4s 119us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0531 - val_acc: 0.9890\n",
      "Epoch 18/20\n",
      "31500/31500 [==============================] - 4s 121us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0515 - val_acc: 0.9898\n",
      "Epoch 19/20\n",
      "31500/31500 [==============================] - 4s 128us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0539 - val_acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23f024e80b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=20, batch_size=256, validation_split=0.25, callbacks=cb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2 = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "       tf.keras.callbacks.ModelCheckpoint(filepath='model/best_model_all.h5', \n",
    "                                                monitor='val_loss',\n",
    "                                                save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 5s 112us/step - loss: 0.0154 - acc: 0.9964\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 5s 111us/step - loss: 0.0087 - acc: 0.9976\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 5s 113us/step - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 5s 110us/step - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 5s 117us/step - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 5s 121us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 5s 112us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 5s 112us/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 5s 112us/step - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 5s 114us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 5s 111us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 5s 111us/step - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 5s 112us/step - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 5s 109us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 5s 110us/step - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 5s 117us/step - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 5s 115us/step - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 5s 117us/step - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 5s 112us/step - loss: 8.5755e-04 - acc: 0.9998\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 5s 113us/step - loss: 0.0014 - acc: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23f6e632a90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=20, batch_size=256, callbacks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Data Augmentation, SGD with restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    \"model/digit-recognizer-TF-Keras-CNN3.h5\",\n",
    "    include_optimizer=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = tf.keras.models.load_model(\"model/digit-recognizer-TF-Keras-CNN3.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = md.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tf.argmax(prediction,axis=1)\n",
    "image_id = np.array(np.arange(1,len(X_test)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert result Tensor back to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "np_label = K.eval(label)\n",
    "result = np.column_stack((image_id, np_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"output/digit-recognizer-TF-Keras-CNN3.csv\", result, fmt=('%d,%d'), delimiter=\",\", \\\n",
    "           header=\"ImageId,Label\",comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!kaggle competitions submit -c digit-recognizer -f output/digit-recognizer-TF-Keras-CNN2.csv -m \"TF/Keras CNN2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score: \n",
    "\n",
    "- 0.98514 (20 epochs, 5 epochs)\n",
    "- ? (30 epochs, 30 epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "5-conv-draft.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
