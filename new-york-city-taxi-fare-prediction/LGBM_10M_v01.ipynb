{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "NROWS = 20_000_000   # NONE: Read all\n",
    "TRAIN_CSV = 'data/nyc-taxi/train.csv'\n",
    "TEST_CSV = 'data/nyc-taxi/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'fare_amount': 'float32',\n",
    "         'passenger_count': 'uint8',\n",
    "         'pickup_longitude': 'float32',\n",
    "         'pickup_latitude': 'float32',\n",
    "         'dropoff_longitude': 'float32',\n",
    "         'dropoff_latitude': 'float32'}\n",
    "\n",
    "cols = ['fare_amount', 'pickup_datetime', 'passenger_count',\n",
    "        'pickup_longitude', 'pickup_latitude',\n",
    "        'dropoff_longitude', 'dropoff_latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(TRAIN_CSV, usecols=cols, dtype=types, nrows=NROWS)\n",
    "train_df['pickup_datetime'] = train_df['pickup_datetime'].str.slice(0, 16)\n",
    "train_df['pickup_datetime'] = pd.to_datetime(train_df['pickup_datetime'], format='%Y-%m-%d %H') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_CSV, dtype=types)\n",
    "test_df.drop('key', axis=1, inplace=True)\n",
    "test_df['pickup_datetime'] = test_df['pickup_datetime'].str.slice(0, 16)\n",
    "test_df['pickup_datetime'] = pd.to_datetime(test_df['pickup_datetime'], format='%Y-%m-%d %H') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6b2990405dc72eb3f55f6048116db2f524f26be8"
   },
   "outputs": [],
   "source": [
    "def clean_feats(df):\n",
    "    \n",
    "    MIN_FARE = 0\n",
    "    MAX_FARE = 150\n",
    "    MIN_PASSENGER = 1\n",
    "    MAX_PASSENGER = 6\n",
    "    MIN_LON = -74.3\n",
    "    MAX_LON = -73.6\n",
    "    MIN_LAT = 40.5\n",
    "    MAX_LAT = 40.9\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.loc[(df[\"fare_amount\"] > MIN_FARE) & (df[\"fare_amount\"] <= MAX_FARE)]\n",
    "    df = df.loc[(df[\"passenger_count\"] >= MIN_PASSENGER) & (df[\"passenger_count\"] <= MAX_PASSENGER)]\n",
    "\n",
    "    df = df[(df.pickup_longitude.between(MIN_LON,MAX_LON)) &\n",
    "            (df.pickup_latitude.between(MIN_LAT,MAX_LAT)) &\n",
    "            (df.dropoff_longitude.between(MIN_LON,MAX_LON)) &\n",
    "            (df.dropoff_latitude.between(MIN_LAT,MAX_LAT))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_distance_feats(df):\n",
    "    df['longitude_distance'] = np.abs(df['pickup_longitude'] - df['dropoff_longitude'])\n",
    "    df['latitude_distance'] = np.abs(df['pickup_latitude'] - df['dropoff_latitude'])\n",
    "    df['manhattan_distance'] = (df['longitude_distance'] + df['latitude_distance'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_datetime_feats(df):\n",
    "    df['year'] = (df['pickup_datetime'].dt.year-2000).astype('uint8') # minus 2000 in order to use uint8 \n",
    "    df['month'] = df['pickup_datetime'].dt.month.astype('uint8')  \n",
    "    df['week'] = df['pickup_datetime'].dt.week.astype('uint8')  \n",
    "    df['dayofweek'] = df['pickup_datetime'].dt.dayofweek.astype('uint8')  \n",
    "    df['day'] = df['pickup_datetime'].dt.day.astype('uint8')  \n",
    "    df['hour'] = df['pickup_datetime'].dt.hour.astype('uint8')  \n",
    "    \n",
    "    df.drop('pickup_datetime', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def dist(pickup_lat, pickup_long, dropoff_lat, dropoff_long):  \n",
    "    return (np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)).astype('float32')  \n",
    "\n",
    "\n",
    "def add_airport_feats(df):\n",
    "    # Distances to nearby airports, and city center\n",
    "    # By reporting distances to these points, the model can somewhat triangulate other locations of interest\n",
    "    nyc = (40.712775,-74.005973) # New York City\n",
    "    jfk = (40.641311,-73.778139) # John F. Kennedy International Airport\n",
    "    ewr = (40.689531,-74.174462) # Newark Liberty International Airport\n",
    "    lgr = (40.776927,-73.873966) # LaGuardia Airport\n",
    "    \n",
    "    df['pickup_distance_to_nyc'] = dist(nyc[0], nyc[1], df['pickup_latitude'], df['pickup_longitude'])\n",
    "    df['dropoff_distance_to_nyc'] = dist(nyc[0], nyc[1], df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "    df['pickup_distance_to_jfk'] = dist(jfk[0], jfk[1], df['pickup_latitude'], df['pickup_longitude'])\n",
    "    df['dropoff_distance_to_jfk'] = dist(jfk[0], jfk[1], df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "    df['pickup_distance_to_ewr'] = dist(ewr[0], ewr[1], df['pickup_latitude'], df['pickup_longitude'])\n",
    "    df['dropoff_distance_to_ewr'] = dist(ewr[0], ewr[1], df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "    df['pickup_distance_to_lgr'] = dist(lgr[0], lgr[1], df['pickup_latitude'], df['pickup_longitude'])\n",
    "    df['dropoff_distance_to_lgr'] = dist(lgr[0], lgr[1], df['dropoff_latitude'], df['dropoff_longitude'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_fare_hike_flag(df):\n",
    "    flag = (((df.year==(2012-2000)) & (df.month>=9)) | (df.year>(2012-2000)))\n",
    "    df['farehike'] = flag \n",
    "    df['farehike'] = df['farehike'].astype('uint8') \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "408288dea6144cbac692a343312fd5917f31fcc6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (20000000, 7)\n",
      "After: (19482643, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\", train_df.shape)\n",
    "\n",
    "# Clean training set\n",
    "train_df = clean_feats(train_df)\n",
    "\n",
    "# Distance Features\n",
    "train_df = add_distance_feats(train_df)\n",
    "test_df = add_distance_feats(test_df)\n",
    "\n",
    "# DateTime Features\n",
    "train_df = add_datetime_feats(train_df)\n",
    "test_df = add_datetime_feats(test_df)\n",
    "\n",
    "# Airport Features\n",
    "train_df  = add_airport_feats(train_df)\n",
    "test_df = add_airport_feats(test_df)\n",
    "\n",
    "# # Fare Hike Flag\n",
    "train_df = add_fare_hike_flag(train_df)\n",
    "test_df = add_fare_hike_flag(test_df)\n",
    "\n",
    "print(\"After:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19482643, 24), (9914, 23))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_feather('tmp/lgbm_train.feather')\n",
    "# test_df.to_feather('tmp/lgbm_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_feather('tmp/lgbm_train.feather')\n",
    "# test_df = pd.read_feather('tmp/lgbm_test.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c68833e7d1151f75db5100c12cd02c30103d1ee0",
    "collapsed": true
   },
   "source": [
    "# LGBM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "87666ffd1c50913abe945539affc29fcd9a03d3b"
   },
   "outputs": [],
   "source": [
    "y = train_df.fare_amount.copy()\n",
    "train_df = train_df[test_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['passenger_count', 'year', 'month', 'week', 'dayofweek', 'day', 'hour', 'farehike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87666ffd1c50913abe945539affc29fcd9a03d3b"
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.03,       # 0.1\n",
    "    'feature_fraction': 0.8,     # 1.0\n",
    "    'bagging_fraction': 0.9,     # 1.0\n",
    "    'bagging_freq': 5,           # 0\n",
    "    'max_bin': 300,              # 255\n",
    "    'num_leaves': 50,            # 31\n",
    "    'num_threads': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train with K-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=555)\n",
    "fold_preds = np.zeros(test_df.shape[0])\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "m_list = []\n",
    "i=1\n",
    "\n",
    "for trn_idx, val_idx in folds.split(train_df):   \n",
    "    \n",
    "    print(f'Split {i}')\n",
    "    \n",
    "    dtrain = lgb.Dataset(train_df.iloc[trn_idx], label=y.iloc[trn_idx], \n",
    "                         feature_name=train_df.columns.tolist(),\n",
    "                         categorical_feature=categorical,\n",
    "                         free_raw_data=False)\n",
    "\n",
    "    dval = lgb.Dataset(train_df.iloc[val_idx], label=y.iloc[val_idx], \n",
    "                       feature_name=train_df.columns.tolist(),\n",
    "                       categorical_feature=categorical,\n",
    "                       free_raw_data=False)\n",
    "\n",
    "    dtrain.construct()\n",
    "    dval.construct()\n",
    "    \n",
    "    m = lgb.train(\n",
    "        params=lgbm_params,\n",
    "        train_set=dtrain,\n",
    "        valid_sets=dval,\n",
    "        num_boost_round=5000, \n",
    "        early_stopping_rounds=125,\n",
    "        verbose_eval=500,\n",
    "        categorical_feature=categorical\n",
    "    )\n",
    "    m_list.append(m)\n",
    "    \n",
    "    fold_preds = m.predict(test_df) \n",
    "    submission = pd.DataFrame(fold_preds, columns=[\"fare_amount\"], index=test_file['key'])\n",
    "    submission.to_csv(f\"submissions/LGBM/v01-Fold{i}.csv\", index=True, header=True)\n",
    "    \n",
    "#     train_preds = m.predict(train_df.iloc[trn_idx])\n",
    "#     oof_preds[val_idx] = m.predict(train_df.iloc[val_idx])\n",
    "#     train_rmse = mean_squared_error(y.iloc[trn_idx], train_preds) ** .5\n",
    "#     val_rmse = mean_squared_error(y.iloc[val_idx], oof_preds[val_idx]) ** .5\n",
    "    \n",
    "#     print(f\"Training RMSE: {train_rmse:.4f}\\t Validation RMSE: {val_rmse:.4f}\")\n",
    "#     print()\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2M rows learning rate 0.05, max_bin 300, num_leaves 50\n",
    "\n",
    "Without Airport and PriceHike:  3.3627, 3.3645, 3.3549, 3.3054, 3.3891      Mean: 3.3553\n",
    "With PriceHike:                 3.3567, 3.3631, 3.3526, 3.3073, 3.3757      Mean: 3.3511\n",
    "With Airport:                   3.3210, 3.3203, 3.3184, 3.2734, 3.3416      Mean: 3.3149\n",
    "With Airport and PriceHike:     3.3216, 3.3168, 3.3139, 3.2705, 3.3339      Mean: 3.3113*\n",
    "\n",
    "Drop dropoff_distance_to_nyc    3.3226, 3.3164, 3.3175, 3.2726, 3.3389      Mean: 3.3136\n",
    "\n",
    "Drop passenger_count            3.3229, 3.3234, 3.3203, 3.2713, 3.3346      Mean: 3.3145"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2M rows learning rate 0.03, max_bin 300, num_leaves 50,\n",
    "feature_fraction 0.8, bagging_fraction 0.9, bagging_freq 5          \n",
    "                                3.3105, 3.3092, 3.3104, 3.2599, 3.32985     Mean: 3.30397*\n",
    "                                \n",
    "2M rows learning rate 0.05, max_bin 300, num_leaves 50,\n",
    "feature_fraction 0.8, bagging_fraction 0.9, bagging_freq 5         \n",
    "                                3.3178, 3.3213, 3.3082, 3.2658, 3.3370       Mean: 3.3100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "20M rows learning rate 0.03, max_bin 300, num_leaves 50,\n",
    "feature_fraction 0.8, bagging_fraction 0.9, bagging_freq 5    \n",
    "                                3.21747,3.19604\n",
    "                        Kaggle  3.21240,3.22194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c574655ba4903afa3fdebe8df9b823051d4b649",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(fold_preds, columns=[\"fare_amount\"], index=test_file['key'])\n",
    "submission.to_csv(\"submissions/LGBM/v01.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.02,       # 0.1\n",
    "    'feature_fraction': 1.0,     # 1.0\n",
    "    'bagging_fraction': 1.0,     # 1.0\n",
    "    'bagging_freq': 0,           # 0\n",
    "    'max_bin': 500,              # 255\n",
    "    'max_depth': 10,              # -1\n",
    "    'num_leaves': 80,            # 31\n",
    "    'num_threads': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(model):\n",
    "    train_rmse = mean_squared_error(y_train, model.predict(X_train)) ** .5\n",
    "    val_rmse = mean_squared_error(y_val, model.predict(X_val)) ** .5\n",
    "    \n",
    "    print(f\"Training RMSE: {train_rmse:.4f}\\t Validation RMSE: {val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "87666ffd1c50913abe945539affc29fcd9a03d3b"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "87666ffd1c50913abe945539affc29fcd9a03d3b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1670902eda0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_train, label=y_train, \n",
    "                     feature_name=train_df.columns.tolist(),\n",
    "                     categorical_feature=categorical,\n",
    "                     free_raw_data=False)\n",
    "\n",
    "dval = lgb.Dataset(X_val, label=y_val, \n",
    "                   feature_name=train_df.columns.tolist(),\n",
    "                   categorical_feature=categorical,\n",
    "                   free_raw_data=False)\n",
    "\n",
    "dtrain.construct()\n",
    "dval.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "87666ffd1c50913abe945539affc29fcd9a03d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 125 rounds.\n",
      "[500]\tvalid_0's rmse: 3.31249\n",
      "[1000]\tvalid_0's rmse: 3.25125\n",
      "[1500]\tvalid_0's rmse: 3.22706\n",
      "[2000]\tvalid_0's rmse: 3.21154\n",
      "[2500]\tvalid_0's rmse: 3.20082\n",
      "[3000]\tvalid_0's rmse: 3.19269\n",
      "[3500]\tvalid_0's rmse: 3.18686\n",
      "[4000]\tvalid_0's rmse: 3.18201\n",
      "[4500]\tvalid_0's rmse: 3.1784\n",
      "[5000]\tvalid_0's rmse: 3.17465\n",
      "[5500]\tvalid_0's rmse: 3.17263\n",
      "[6000]\tvalid_0's rmse: 3.17051\n",
      "[6500]\tvalid_0's rmse: 3.16887\n",
      "[7000]\tvalid_0's rmse: 3.16711\n",
      "[7500]\tvalid_0's rmse: 3.16572\n",
      "[8000]\tvalid_0's rmse: 3.16444\n",
      "[8500]\tvalid_0's rmse: 3.16314\n",
      "[9000]\tvalid_0's rmse: 3.16195\n",
      "[9500]\tvalid_0's rmse: 3.16073\n",
      "[10000]\tvalid_0's rmse: 3.15992\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9992]\tvalid_0's rmse: 3.15991\n",
      "Wall time: 1h 52min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = lgb.train(\n",
    "    params=lgbm_params,\n",
    "    train_set=dtrain,\n",
    "    valid_sets=dval,\n",
    "    num_boost_round=10_000, \n",
    "    early_stopping_rounds=125,\n",
    "    verbose_eval=500,\n",
    "    categorical_feature=categorical\n",
    ")\n",
    "\n",
    "# print_scores(m)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.03,       # 0.1\n",
    "    'feature_fraction': 1.0,     # 1.0\n",
    "    'bagging_fraction': 1.0,     # 1.0\n",
    "    'bagging_freq': 0,           # 0\n",
    "    'max_bin': 500,              # 255\n",
    "    'max_depth': 10,              # -1\n",
    "    'num_leaves': 80,            # 31\n",
    "    'num_threads': 4,\n",
    "}\n",
    "\n",
    "Training until validation scores don't improve for 125 rounds.\n",
    "[500]\tvalid_0's rmse: 3.2726\n",
    "[1000]\tvalid_0's rmse: 3.22673\n",
    "[1500]\tvalid_0's rmse: 3.20544"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[500]\tvalid_0's rmse: 3.34391\n",
    "[1000]\tvalid_0's rmse: 3.26922\n",
    "[1500]\tvalid_0's rmse: 3.23715\n",
    "[2000]\tvalid_0's rmse: 3.219\n",
    "[2500]\tvalid_0's rmse: 3.20747\n",
    "[3000]\tvalid_0's rmse: 3.19962\n",
    "[3500]\tvalid_0's rmse: 3.19454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = m.predict(test_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "4c574655ba4903afa3fdebe8df9b823051d4b649"
   },
   "outputs": [],
   "source": [
    "test_key = pd.read_csv(TEST_CSV)\n",
    "submission = pd.DataFrame(predictions, columns=[\"fare_amount\"], index=test_key.key)\n",
    "submission.to_csv(\"submissions/LGBM/v01.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-27 13:08:24.0000002</th>\n",
       "      <td>9.650425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-27 13:08:24.0000003</th>\n",
       "      <td>10.500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-08 11:53:44.0000002</th>\n",
       "      <td>4.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 21:12:12.0000002</th>\n",
       "      <td>9.078172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01 21:12:12.0000003</th>\n",
       "      <td>16.284248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fare_amount\n",
       "key                                     \n",
       "2015-01-27 13:08:24.0000002     9.650425\n",
       "2015-01-27 13:08:24.0000003    10.500041\n",
       "2011-10-08 11:53:44.0000002     4.076000\n",
       "2012-12-01 21:12:12.0000002     9.078172\n",
       "2012-12-01 21:12:12.0000003    16.284248"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
